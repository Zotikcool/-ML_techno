{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 21 октября 2019, 08:30 \n",
    "\n",
    "**Штраф за опоздание:** по 0.5 балла за 24 часа задержки. Через 10 дней домашнее задание сгорает.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "\n",
    "[ML0919, Задание 1] Фамилия Имя.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -0.5 баллов\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw1.ipynb) -0.5 баллов\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -0.5 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_mldata, fetch_20newsgroups\n",
    "\n",
    "from sklearn.neighbors.base import NeighborsBase, KNeighborsMixin, SupervisedIntegerMixin \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 1 (1 балл)\n",
    "Реализовать KNN в классе MyKNeighborsClassifier (обязательное условие: точность не ниже sklearn реализации)\n",
    "Разберитесь самостоятельно, какая мера расстояния используется в KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой мерой. Самостоятельно разберитесь, как считается score из KNeighborsClassifier и реализуйте аналог в своём классе. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "\n",
    "class MyKNeighborsClassifier(NeighborsBase, KNeighborsMixin,\n",
    "                             SupervisedIntegerMixin, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, n_neighbors, algorithm='brute'):\n",
    "        self._k = n_neighbors\n",
    "        self.alg = algorithm\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.train = np.array(X, dtype=float)\n",
    "        self.res = np.array(y)\n",
    "        self.size = self.train.shape[0]\n",
    "        self.unclasses = np.unique(y)\n",
    "        self.tree = KDTree(self.train, leaf_size=30)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.alg == \"brute\":\n",
    "            d = squareform(pdist(np.concatenate((self.train, X), axis=0)))\n",
    "            d = d[self.size:, :self.size]\n",
    "            d = d.argpartition(self._k)[:, :self._k]\n",
    "            f = self.res[d]\n",
    "            ans = []\n",
    "            for obj in f:\n",
    "                values, counts = np.unique(obj, return_counts=True)\n",
    "                ind = np.argmax(counts)\n",
    "                ans.append(values[ind])\n",
    "        if self.alg == \"kd_tree\":\n",
    "            ans = []\n",
    "            _, d = self.tree.query(X, k=self._k)\n",
    "            f = self.res[d]\n",
    "            for obj in f:\n",
    "                values, counts = np.unique(obj, return_counts=True)\n",
    "                ind = np.argmax(counts)\n",
    "                ans.append(values[ind])\n",
    "        return ans\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        ans = np.zeros(shape=(np.shape(X)[0], self.unclasses.shape[0]))\n",
    "        if self.alg == \"brute\":\n",
    "            d = squareform(pdist(np.concatenate((self.train, X), axis=0)))\n",
    "            d = d[self.size:, :self.size]\n",
    "            d = d.argpartition(self._k)[:, :self._k]\n",
    "            f = self.res[d]\n",
    "            for i in range(f.shape[0]):\n",
    "                values, counts = np.unique(f[i], return_counts=True)\n",
    "                ans[i, values] = counts / self._k\n",
    "        if self.alg == \"kd_tree\":\n",
    "            _, d = self.tree.query(X, k=self._k)\n",
    "            f = self.res[d]\n",
    "            for i in range(f.shape[0]):\n",
    "                values, counts = np.unique(f[i], return_counts=True)\n",
    "                ans[i, values] = counts / self._k\n",
    "        return ans\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IRIS**\n",
    "\n",
    "В библиотеке scikit-learn есть несколько датасетов из коробки. Один из них [Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "print(my_clf.score(X_test, y_test))\n",
    "print(clf.score(X_test,y_test))\n",
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (0.5 балла)**\n",
    "\n",
    "Давайте попробуем добиться скорости работы на fit, predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 532 µs\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.19 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 2, 1, 1, 0, 1, 2, 2, 2, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 885 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 2, 1, 1, 0, 1, 2, 2, 2, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 696 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 3 (1 балл)\n",
    "Добавьте algorithm='kd_tree' в реализацию KNN (использовать KDTree из sklearn.neighbors). Необходимо добиться скорости работы на fit,  predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 2, 2, 2, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 998 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 0, 1, 0, 0, 2, 1, 2, 0, 1, 2, 2, 2, 1, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 698 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2.5 балла)**\n",
    "\n",
    "Рассмотрим новый датасет 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newsgroups['data']\n",
    "target = newsgroups['target']              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведите во всех документах все буквы в нижний регистр и замените во всех документах символы, не\n",
    "являющиеся буквами и цифрами, на пробелы. Далее разбейте текста по пробельным символам на токены(термы/слова). Удалите текста, содержащие только пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tok = [text.lower() for text in data]\n",
    "n = len(data_tok)\n",
    "i = 0\n",
    "while i < n:\n",
    "    data_tok[i] = ''.join([c if c.isalpha() or c.isdigit() else ' ' for c in data_tok[i]])\n",
    "    data_tok[i] = data_tok[i].split()\n",
    "    if data_tok[i] == []:\n",
    "        del data_tok[i]\n",
    "        target = np.delete(target, i)\n",
    "        n -= 1\n",
    "    else:\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
    "assert all(map(lambda l: not is_latin(l) or l.islower() , map(' '.join, data_tok))), \"please make sure that you lowercase the data and drop spaced texts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте датасет в разреженную матрицу scipy.sparse.csr_matrix, где значение x в позиции (i, j)\n",
    "означает, что в документе i слово j встретилось x раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "dic_count = defaultdict(int)\n",
    "for text in data_tok:\n",
    "    for word in text:\n",
    "        dic_count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = list(dic_count.items())\n",
    "for (word, value) in temp_list:\n",
    "    if value <= 9:\n",
    "        del dic_count[word]\n",
    "    if value >= 2500:\n",
    "        del dic_count[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "temp_list = list(dic_count.items())\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "for d in data_tok:\n",
    "    for term in d:\n",
    "        if term not in dic_count:\n",
    "            continue\n",
    "        index = temp_list.index((term, dic_count[term]))\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "\n",
    "matrix = csr_matrix((data, indices, indptr), dtype=int).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Так мы получили векторное предст авление наших текстов. Значит можно приступать к задаче обучения модели*w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте разбиение выборки для кросс-валидации на 3 фолдах. Разрешено использовать sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 3668  3669  3670 ... 11001 11002 11003] TEST: [   0    1    2 ... 3665 3666 3667]\n",
      "TRAIN: [    0     1     2 ... 11001 11002 11003] TEST: [3668 3669 3670 ... 7333 7334 7335]\n",
      "TRAIN: [   0    1    2 ... 7333 7334 7335] TEST: [ 7336  7337  7338 ... 11001 11002 11003]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(matrix):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = matrix[train_index], matrix[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите метод, позволяющий найти оптимальное количество ближайших соседей(дающее максимальный score в среднем на валидации на 3 фолдах).\n",
    "Постройте график зависимости среднего score от количества соседей. Можно рассмотреть число соседей от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как изменится качество на валидации, если:\n",
    "\n",
    "1. Используется косинусная метрика вместо евклидовой.\n",
    "2. К текстам применяется TfIdf преобразование( sklearn.feature_extraction.text.TfidfTransformer)\n",
    "\n",
    "Сравните модели, выберите лучшую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим  теперь test  часть нашей выборки и преобразуем её аналогично с train частью. Не забудьте, что наборы слов в train и test части могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='test',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество(score) вашей лучшей модели на test части датасета. Отличается ли оно от кросс-валидации? Попробуйте сделать выводы, почему отличается качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
